============================================================
============================================================

üß† Monitor de Atenci√≥n Visual en Tiempo Real

Este proyecto implementa un sistema de monitoreo de atenci√≥n en tiempo real utilizando visi√≥n por computadora con MediaPipe, visualizaci√≥n con Streamlit y procesamiento con OpenCV.

============================================================
============================================================

üéØ Objetivo

Detectar si un usuario est√° prestando atenci√≥n frente a la c√°mara, evaluando la posici√≥n del rostro y la orientaci√≥n de la mirada, con validaci√≥n adicional mediante segmentaci√≥n sem√°ntica para asegurar que hay una persona real en escena.

============================================================
============================================================

üîç Funcionalidad

Detecci√≥n facial en vivo con MediaPipe FaceMesh

Segmentaci√≥n de personas con MediaPipe SelfieSegmentation, para validar que haya una persona real frente a c√°mara

Evaluaci√≥n del √≠ndice de atenci√≥n con criterios de posici√≥n de nariz y ojos

Penalizaciones si la cabeza est√° baja o la mirada desviada

Visualizaci√≥n del an√°lisis en tiempo real con OpenCV + gr√°fico de atenci√≥n con matplotlib

Al detener el monitoreo, generaci√≥n de un gr√°fico final de resumen.

============================================================
============================================================

üóÇÔ∏è Estructura del proyecto

monitor_atencion/
‚îú‚îÄ‚îÄ main.py                 # Interfaz principal con Streamlit
‚îú‚îÄ‚îÄ detector.py             # L√≥gica de atenci√≥n y landmarks faciales
‚îú‚îÄ‚îÄ segmentacion.py         # Validaci√≥n de presencia humana por segmentaci√≥n
‚îú‚îÄ‚îÄ graficos.py             # Visualizaci√≥n del √≠ndice de atenci√≥n
‚îú‚îÄ‚îÄ requirements.txt        # Lista de dependencias
‚îî‚îÄ‚îÄ README.md               # Documentaci√≥n del proyecto

============================================================
============================================================

‚ñ∂Ô∏è Instrucciones de uso

Instalar dependencias:

pip install -r requirements.txt

Ejecutar el sistema:

streamlit run main.py

Si no funciona, ejecutar python -m streamlit run main.py

============================================================
============================================================

‚öôÔ∏è Dependencias principales

- streamlit: Interfaz web interactiva
- opencv-python: Captura y procesamiento de video
- mediapipe: Detecci√≥n facial y segmentaci√≥n
- numpy: C√°lculos num√©ricos
- matplotlib: Gr√°ficos en tiempo real

============================================================
============================================================

üß© Contenidos de Clases Aplicados

‚úÖ Clase 7: Reconocimiento de patrones

Concepto aplicado: Detecci√≥n de patrones faciales mediante landmarks.

En el proyecto: Se utiliza MediaPipe FaceMesh para detectar 468 puntos clave del rostro, permitiendo identificar la posici√≥n de nariz, ojos, frente y barbilla para evaluar la orientaci√≥n facial.

‚úÖ Clase 8: Visi√≥n por computadora

Concepto aplicado: Procesamiento de im√°genes y video con OpenCV.

En el proyecto: Se captura video de la webcam frame a frame, se convierte de BGR a RGB para MediaPipe, se aplica flip horizontal (efecto espejo), y se dibujan anotaciones visuales sobre cada frame.

‚úÖ Clase 9: Inteligencia artificial aplicada

Concepto aplicado: Redes neuronales convolucionales y aprendizaje profundo.

En el proyecto: MediaPipe FaceMesh utiliza internamente modelos de deep learning para detectar landmarks faciales. MediaPipe SelfieSegmentation usa CNNs para segmentaci√≥n sem√°ntica persona/fondo.

‚úÖ Clase 10: Librer√≠as especializadas

Concepto aplicado: Uso de librer√≠as de visi√≥n por computadora.

En el proyecto: Se integran OpenCV (captura de video, procesamiento de frames), MediaPipe (detecci√≥n facial y segmentaci√≥n), NumPy (operaciones con arrays) y Matplotlib (visualizaci√≥n de gr√°ficos).

‚úÖ Clase 11: Detecci√≥n en tiempo real

Concepto aplicado: An√°lisis continuo frame a frame con feedback inmediato.

En el proyecto: El sistema procesa la webcam en vivo, evaluando la atenci√≥n en cada frame y actualizando el indicador visual y el gr√°fico en tiempo real.

‚úÖ Clase 12: An√°lisis de comportamiento

Concepto aplicado: M√©tricas de atenci√≥n y evaluaci√≥n conductual basada en im√°genes.

En el proyecto: Se implementa un √≠ndice de atenci√≥n (0-100%) basado en la posici√≥n centrada de nariz y ojos, con penalizaciones por cabeza baja o mirada desviada. Se genera un resumen estad√≠stico al finalizar.

============================================================
============================================================

üë§ Autor

Desarrollado por Nicol√°s Bargioni | A√±o 2025
ISSD: Inteligencia Artificial y Ciencia de Datos
Materia: Procesamiento de Im√°genes

============================================================
============================================================# pim-2
